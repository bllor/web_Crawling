네이버금융_with_requests

html태그가 2개 이상 존재하는 경우가 있는데, html태그 내에 iframe태그가 있을 경우 html태그가 1개 이상 존재할 수도 있다.

table = soup.select("table.type2 > tr")
<table calss = "type2">
	<tr>
tr태그의 자신들 데이터를 가져온다

tr태그 중에 데이터가 없거나 필요없는 태그를 제거하는 방법
데이터가 있는 태그들은 <tr onmouseover=mouseOver(this)>의 형태로 되어 있어서 가져올 때
tr_elements = soup.select("table.type2 > tr[onmouseover='mouseOver(this)']")
처럼 가져오면 된다.


판다스 라이브러리 이용
데이터를 관리하기 용이하기 위해서 판다스를 사용한다

import pandas as pd
df = pd.DataFrame(리스트, columns = [칼럼1,칼럼2,칼럼3])
print(df)를 할 경우 엄청 깔끔하게 출력된다.

df.dtypes를 하면 데이터 타입이 나온다.


[json형태의 재무재표 데이터 가져오기]
json: 키-값 쌍으로 이루어진 데이터 오브젝트를 전달하기 위해 인간이 읽을 수 있는 텍스트를 사용하는 개방형 표준 포멧
json은 딕셔너리.
dict.keys() : 키를 보여준다.

json을 파이썬에서 읽기 
import json
json.loads(읽을 데이터)

딕셔너리를 json으로 바꾸기
json.dump(변경할 데이터 )

json을 저장했다가 데이터를 전처리함


[정규표현식]
정규표현식 : regular expression

*
'70,000'을 int로 변환할 경우 ,를 제거해야한다.


*
total_data_list = []
for e in tr_elements:
    td_elements = e.select("td")
    data_list = []
    for td_e in td_elements:
        data_list.append(td_e.text.strip())
    total_data_list.append(data_list)

tr태그의 데이터를 불러올 때
e.text.strip()을 할 경우 <td>태그의 데이터를 불러오는데, 이렇게 할 경우 데이터의 빈칸이 처리되지 않는 이슈가 존재한다.
이럴 경우 다시 <td>태그만을 선택하여 하나씩 조회하며 빈칸을 제거해주어야 한다.

*
requests에서 url을 요청할 때 브라우저가 요청하는 것과 유사하게 만들어야 하는데,
header를 추가하면 유사해진다.

header는 개발자도구- 네트워크에서 requests header를 그대로 복사해와서 사용한다.
:이나 accept, cookie로 시작하는 key는 중요하지 않다.

referer , user-agent, upgrade-insecure-requests1 등은 많이 사용되는 것이므로 header에서 제외하지 않는다.
사이트마다 header에 필요한 값이 다르다.

*
requests로 url을 요청하는 것이 브라우저에서 서버로 요청하는 것을 모방하는 것인데
for문을 통해서 요청을 하게 된다면 엄청 빠르게 요청이 되어서
서버에서는 요청이 갑자기 증가할 경우 ip를 차단하거나 응답을 주지 않을 수 있다.

*
for i,e in euemerate([1,2,4,5]):
print(i,e)
0 1
1 2
2 4
3 5
로 출력된다.


